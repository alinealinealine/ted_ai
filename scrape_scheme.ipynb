{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file is to scrape the scheme website filtered by agriculture and environment. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to scrape single-website content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'scraped_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL = \"https://www.myscheme.gov.in/schemes/e-nam\"\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.3'}\n",
    "\n",
    "response = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Locate the outer div using its class attributes\n",
    "    outer_div = soup.find('div', class_='w-full flex flex-row justify-between items-start mb-5')\n",
    "    \n",
    "    if outer_div:\n",
    "        # Extract state and scheme_name from within the outer div\n",
    "        state_elem = outer_div.find('h2', class_='text-darkIndigo-900 text-sm')\n",
    "        scheme_name_elem = outer_div.find('h1', class_='font-bold text-green-600 text-xl sm:text-2xl mt-1')\n",
    "\n",
    "        # Use a ternary conditional to handle potential None values\n",
    "        state = state_elem.text.strip() if state_elem else \"N/A\"\n",
    "        scheme_name = scheme_name_elem.text.strip() if scheme_name_elem else \"N/A\"\n",
    "\n",
    "        # Extract the 'sources' link\n",
    "        sources_link = soup.find('a', class_='flex flex-row items-center py-4 justify-start hover:underline underline-offset-2')['href']\n",
    "\n",
    "        # Find all divs with class 'pt-10'\n",
    "        divs = soup.find_all('div', class_='pt-10')\n",
    "\n",
    "        # Extracting the id and the content of the div\n",
    "        data = {'url': URL, 'state': state, 'scheme_name': scheme_name, 'sources': sources_link}  # Initialize with URL, state, scheme_name, and sources_link\n",
    "        for div in divs:\n",
    "            div_id = div.get('id')\n",
    "            if div_id:\n",
    "                # Exclude content from <div class=\"mb-2\" ...>\n",
    "                excluded_content = div.find('div', class_='mb-2')\n",
    "                if excluded_content:\n",
    "                    excluded_content.extract()  # Remove the unwanted content\n",
    "\n",
    "                # Extract content from <ol> and <li> elements\n",
    "                ol_content = div.find('ol')\n",
    "                if ol_content:\n",
    "                    data[div_id] = ' '.join([li.text.strip() for li in ol_content.find_all('li')])\n",
    "\n",
    "        # Convert the data dictionary to a DataFrame\n",
    "        df = pd.DataFrame([data])\n",
    "\n",
    "        # Save the data to a CSV file\n",
    "        df.to_csv(\"scraped_data.csv\", index=False)\n",
    "        print(\"Data saved to 'scraped_data.csv'.\")\n",
    "\n",
    "    else:\n",
    "        print(\"Couldn't find the outer div element.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>state</th>\n",
       "      <th>scheme_name</th>\n",
       "      <th>sources</th>\n",
       "      <th>details</th>\n",
       "      <th>eligibility</th>\n",
       "      <th>applicationProcess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.myscheme.gov.in/schemes/e-nam</td>\n",
       "      <td>Ministry Of Agriculture and Farmers Welfare</td>\n",
       "      <td>National Agriculture Market</td>\n",
       "      <td>https://enam.gov.in/web/docs/namguidelines.pdf</td>\n",
       "      <td>To integrate markets first at the level of the...</td>\n",
       "      <td>Single trading license to be valid across the ...</td>\n",
       "      <td>Users can register by Clicking  http://enam.go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         url   \n",
       "0  https://www.myscheme.gov.in/schemes/e-nam  \\\n",
       "\n",
       "                                         state                  scheme_name   \n",
       "0  Ministry Of Agriculture and Farmers Welfare  National Agriculture Market  \\\n",
       "\n",
       "                                          sources   \n",
       "0  https://enam.gov.in/web/docs/namguidelines.pdf  \\\n",
       "\n",
       "                                             details   \n",
       "0  To integrate markets first at the level of the...  \\\n",
       "\n",
       "                                         eligibility   \n",
       "0  Single trading license to be valid across the ...  \\\n",
       "\n",
       "                                  applicationProcess  \n",
       "0  Users can register by Clicking  http://enam.go...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the relevant links (schemes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First page extract link adn keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://www.myscheme.gov.in/schemes/bjrcy': ['Hostel', 'Student'], 'https://www.myscheme.gov.in/schemes/onorc': ['Migrant Workers', 'Ration Card'], 'https://www.myscheme.gov.in/schemes/nos-sc': ['Degree', 'International Education', 'PhD', 'Post-Graduation', 'Scheduled Caste', 'Scholarship', 'Student', 'Tuition Fees'], 'https://www.myscheme.gov.in/schemes/kvsy': ['Financial Assistance', 'Girl', 'Kanya', 'Marriage', 'Vivah'], 'https://www.myscheme.gov.in/schemes/uky': ['Deprivation Of Liberty', 'Domestic Violence', 'Mental Abuse', 'Physical Abuse', 'Sexual Abuse'], 'https://www.myscheme.gov.in/schemes/pmssu': ['Disabled Welfare', 'Education', 'Financial Assistance', 'Student Finance'], 'https://www.myscheme.gov.in/schemes/spaddap': ['Assistive Devices', 'Differently Abled Persons', 'Disability', 'PwD', 'Social Welfare'], 'https://www.myscheme.gov.in/schemes/famdpwog': ['Financial Asisstance', 'Girl Child', 'Marriage', 'Orphan', 'Widow'], 'https://www.myscheme.gov.in/schemes/jms-11and12': ['Class XI', 'Class XII', 'E-medhabruti', 'Scholarship', 'Students'], 'https://www.myscheme.gov.in/schemes/ma-maha': ['Award', 'Education', 'School', 'Student With Disability']}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "# Initialize the Chrome webdriver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Navigate to the website\n",
    "page_first = \"https://www.myscheme.gov.in/search\"\n",
    "driver.get(page_first)\n",
    "\n",
    "# Wait for the elements to load\n",
    "wait = WebDriverWait(driver, 20)\n",
    "\n",
    "# Wait specifically for the first card to appear before continuing\n",
    "wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.mx-auto.rounded-xl.shadow-md')))\n",
    "\n",
    "# Initialize a dictionary to store URLs as keys and keywords as values\n",
    "url_keywords_map = {}\n",
    "\n",
    "# Find all the main card divs on the page\n",
    "card_divs = driver.find_elements(By.CSS_SELECTOR, 'div.mx-auto.rounded-xl.shadow-md')\n",
    "\n",
    "for card in card_divs:\n",
    "    # For each card, extract the URL\n",
    "    url_element = card.find_element(By.CSS_SELECTOR, 'h2 a')\n",
    "    url = url_element.get_attribute('href')\n",
    "\n",
    "    # Extract all the keyword divs\n",
    "    keyword_divs = card.find_elements(By.CSS_SELECTOR, 'div.text-gray-800.bg-gray-100.rounded')  # Notice the change here\n",
    "    \n",
    "    # Extract the text (i.e., the keyword) from each keyword div and store them in a list\n",
    "    keywords = [div.text for div in keyword_divs]\n",
    "\n",
    "    # Store the keywords list in our dictionary with the URL as the key\n",
    "    url_keywords_map[url] = keywords\n",
    "\n",
    "print(url_keywords_map)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it with all next pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 2\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 3\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 4\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 5\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 6\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 7\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 8\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 9\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 10\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 11\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 12\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 13\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 14\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 15\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 16\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 17\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 18\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 19\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 20\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 21\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 22\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 23\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 24\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 25\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 26\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 27\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 28\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 29\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 30\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 31\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 32\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 33\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 34\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 35\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 36\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 37\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 38\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 39\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 40\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 41\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 42\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 43\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 44\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 45\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 46\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 47\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 48\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 49\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 50\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 51\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 52\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 53\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 54\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 55\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 56\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 57\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 58\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 59\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 60\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 61\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 62\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 63\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 64\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 65\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 66\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 67\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 68\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 69\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 70\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 71\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 72\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 73\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 74\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 75\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 76\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 77\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 78\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 79\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 80\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 81\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 82\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 83\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 84\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 85\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 86\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 87\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 88\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 89\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 90\n",
      "Extracted 9 items from the page.\n",
      "Clicked to navigate to page 91\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 92\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 93\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 94\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 95\n",
      "Extracted 10 items from the page.\n",
      "Clicked to navigate to page 96\n",
      "Extracted 10 items from the page.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "import time\n",
    "\n",
    "page_first = \"https://www.myscheme.gov.in/search\"\n",
    "\n",
    "def click_next_page(driver, current_page):\n",
    "    try:\n",
    "        # Click on the next page number based on the current_page\n",
    "        next_page_num = current_page + 1\n",
    "        next_page_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, f\"//li[text()='{next_page_num}']\")))\n",
    "        \n",
    "        # Try scrolling the element into view\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", next_page_button)\n",
    "        time.sleep(2)  # Wait a bit for any potential overlay to disappear\n",
    "        \n",
    "        # Try JavaScript click if regular click fails\n",
    "        try:\n",
    "            next_page_button.click()\n",
    "        except ElementClickInterceptedException:\n",
    "            driver.execute_script(\"arguments[0].click();\", next_page_button)\n",
    "        \n",
    "        print(f\"Clicked to navigate to page {next_page_num}\")  # Debugging Output\n",
    "        return True\n",
    "    except (NoSuchElementException, TimeoutException):\n",
    "        print(f\"Failed to navigate to page {next_page_num}\")  # Debugging Output\n",
    "        return False\n",
    "    except ElementClickInterceptedException:\n",
    "        # You might add more specific handling for this exception here if needed\n",
    "        print(f\"Element was obscured when trying to navigate to page {next_page_num}\")\n",
    "        return False\n",
    "\n",
    "def extract_content_from_current_page(driver):\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    card_divs = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.mx-auto.rounded-xl.shadow-md')))\n",
    "    \n",
    "    url_keywords_map = {}\n",
    "\n",
    "    for card in card_divs:\n",
    "        url_element = card.find_element(By.CSS_SELECTOR, 'h2 a')\n",
    "        url = url_element.get_attribute('href')\n",
    "        keyword_divs = card.find_elements(By.CSS_SELECTOR, 'div.text-gray-800.bg-gray-100.rounded')\n",
    "        keywords = [div.text for div in keyword_divs]\n",
    "        url_keywords_map[url] = keywords\n",
    "\n",
    "    print(f\"Extracted {len(url_keywords_map)} items from the page.\")  # Debugging Output\n",
    "\n",
    "    return url_keywords_map\n",
    "\n",
    "def main():\n",
    "    # Initialize WebDriver\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(page_first)\n",
    "\n",
    "    current_page = 1\n",
    "    all_content = []\n",
    "    \n",
    "    all_content.append(extract_content_from_current_page(driver))\n",
    "\n",
    "    # Try navigating using pagination numbers\n",
    "    while click_next_page(driver, current_page):\n",
    "        current_page += 1\n",
    "        # Wait until one of the expected elements of the new page is present\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.mx-auto.rounded-xl.shadow-md')))\n",
    "        all_content.append(extract_content_from_current_page(driver))\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    for content in all_content:\n",
    "        print(content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click the checkbox as filter to find schmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://myscheme.gov.in/search\")\n",
    "\n",
    "# Wait for page to load\n",
    "WebDriverWait(driver, 10).until(EC.title_contains(\"Search Schemes\")) \n",
    "\n",
    "# Click checkbox by partial text match\n",
    "checkboxes = driver.find_elements(By.XPATH, \"//span[contains(text(),'gri')]\")\n",
    "for checkbox in checkboxes:\n",
    "    checkbox.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=118.0.5993.70)\nStacktrace:\n0   chromedriver                        0x0000000104b5c510 chromedriver + 4310288\n1   chromedriver                        0x0000000104b544bc chromedriver + 4277436\n2   chromedriver                        0x00000001047879c4 chromedriver + 293316\n3   chromedriver                        0x00000001047ce798 chromedriver + 583576\n4   chromedriver                        0x00000001047c2eac chromedriver + 536236\n5   chromedriver                        0x00000001047c2774 chromedriver + 534388\n6   chromedriver                        0x0000000104807e60 chromedriver + 818784\n7   chromedriver                        0x00000001047c0fd0 chromedriver + 528336\n8   chromedriver                        0x00000001047c1e7c chromedriver + 532092\n9   chromedriver                        0x0000000104b22834 chromedriver + 4073524\n10  chromedriver                        0x0000000104b267fc chromedriver + 4089852\n11  chromedriver                        0x0000000104b26c58 chromedriver + 4090968\n12  chromedriver                        0x0000000104b2c8f8 chromedriver + 4114680\n13  chromedriver                        0x0000000104b27234 chromedriver + 4092468\n14  chromedriver                        0x0000000104b01604 chromedriver + 3937796\n15  chromedriver                        0x0000000104b43ee8 chromedriver + 4210408\n16  chromedriver                        0x0000000104b44064 chromedriver + 4210788\n17  chromedriver                        0x0000000104b54134 chromedriver + 4276532\n18  libsystem_pthread.dylib             0x0000000189183034 _pthread_start + 136\n19  libsystem_pthread.dylib             0x000000018917de3c thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m     label_element \u001b[39m=\u001b[39m WebDriverWait(driver, \u001b[39m10\u001b[39m)\u001b[39m.\u001b[39muntil(EC\u001b[39m.\u001b[39mpresence_of_element_located((By\u001b[39m.\u001b[39mXPATH, \u001b[39m\"\u001b[39m\u001b[39m//span[contains(text(), \u001b[39m\u001b[39m'\u001b[39m\u001b[39mAgri\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[0;32m---> 17\u001b[0m     label_element\u001b[39m.\u001b[39;49mclick()\n\u001b[1;32m     18\u001b[0m \u001b[39mexcept\u001b[39;00m (NoSuchElementException, TimeoutException):\n\u001b[1;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLabel not found. The checkbox might not exist or the text might be different.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:94\u001b[0m, in \u001b[0;36mWebElement.click\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclick\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(Command\u001b[39m.\u001b[39;49mCLICK_ELEMENT)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    393\u001b[0m     params \u001b[39m=\u001b[39m {}\n\u001b[1;32m    394\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id\n\u001b[0;32m--> 395\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent\u001b[39m.\u001b[39;49mexecute(command, params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:346\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    344\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[1;32m    347\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    348\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=118.0.5993.70)\nStacktrace:\n0   chromedriver                        0x0000000104b5c510 chromedriver + 4310288\n1   chromedriver                        0x0000000104b544bc chromedriver + 4277436\n2   chromedriver                        0x00000001047879c4 chromedriver + 293316\n3   chromedriver                        0x00000001047ce798 chromedriver + 583576\n4   chromedriver                        0x00000001047c2eac chromedriver + 536236\n5   chromedriver                        0x00000001047c2774 chromedriver + 534388\n6   chromedriver                        0x0000000104807e60 chromedriver + 818784\n7   chromedriver                        0x00000001047c0fd0 chromedriver + 528336\n8   chromedriver                        0x00000001047c1e7c chromedriver + 532092\n9   chromedriver                        0x0000000104b22834 chromedriver + 4073524\n10  chromedriver                        0x0000000104b267fc chromedriver + 4089852\n11  chromedriver                        0x0000000104b26c58 chromedriver + 4090968\n12  chromedriver                        0x0000000104b2c8f8 chromedriver + 4114680\n13  chromedriver                        0x0000000104b27234 chromedriver + 4092468\n14  chromedriver                        0x0000000104b01604 chromedriver + 3937796\n15  chromedriver                        0x0000000104b43ee8 chromedriver + 4210408\n16  chromedriver                        0x0000000104b44064 chromedriver + 4210788\n17  chromedriver                        0x0000000104b54134 chromedriver + 4276532\n18  libsystem_pthread.dylib             0x0000000189183034 _pthread_start + 136\n19  libsystem_pthread.dylib             0x000000018917de3c thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Setting up the Chrome driver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.myscheme.gov.in/search\")\n",
    "\n",
    "# Wait for the label to be present using WebDriverWait\n",
    "try:\n",
    "    label_element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//span[contains(text(), 'Agri')]\")))\n",
    "    label_element.click()\n",
    "except (NoSuchElementException, TimeoutException):\n",
    "    print(\"Label not found. The checkbox might not exist or the text might be different.\")\n",
    "    driver.quit()\n",
    "    exit()\n",
    "\n",
    "# Wait for a moment to ensure data loads\n",
    "time.sleep(5)\n",
    "\n",
    "# Extract URLs\n",
    "schemes = driver.find_elements(By.XPATH, \"//div[@class='scheme-box']//h2/a\")\n",
    "urls = [scheme.get_attribute(\"href\") for scheme in schemes]\n",
    "\n",
    "# Save to CSV\n",
    "with open('scraped_data.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"URL\"])\n",
    "    for url in urls:\n",
    "        writer.writerow([url])\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n",
    "\n",
    "print(\"Data saved to 'scraped_data.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
